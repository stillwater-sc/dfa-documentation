<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.110.0"><meta name=generator content="Relearn 5.10.2+tip"><meta name=description content="Introduction and educational site for the design and optimization of parallel domain flow algorithms"><meta name=author content="E. Theodore L. Omtzigt"><title>Derivation - Domain Flow Architecture</title><link href=../../images/favicon.png?1675124967 rel=icon type=image/png><link href=../../css/fontawesome-all.min.css?1675124967 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=../../css/fontawesome-all.min.css?1675124967 rel=stylesheet></noscript><link href=../../css/featherlight.min.css?1675124967 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=../../css/featherlight.min.css?1675124967 rel=stylesheet></noscript><link href=../../css/auto-complete.css?1675124967 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=../../css/auto-complete.css?1675124967 rel=stylesheet></noscript><link href=../../css/perfect-scrollbar.min.css?1675124967 rel=stylesheet><link href=../../css/nucleus.css?1675124967 rel=stylesheet><link href=../../css/fonts.css?1675124967 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=../../css/fonts.css?1675124967 rel=stylesheet></noscript><link href=../../css/theme.css?1675124967 rel=stylesheet><link href=../../css/theme-blue.css?1675124967 rel=stylesheet id=variant-style><link href=../../css/ie.css?1675124967 rel=stylesheet><link href=../../css/variant.css?1675124967 rel=stylesheet><link href=../../css/print.css?1675124967 rel=stylesheet media=print><script src=../../js/url.js?1675124967></script>
<script src=../../js/variant.js?1675124967></script>
<script>window.index_json_url="../../index.json";var root_url="../../",baseUriFull,baseUri=root_url.replace(/\/$/,"");window.T_Copy_to_clipboard="Copy to clipboard",window.T_Copied_to_clipboard="Copied to clipboard!",window.T_Copy_link_to_clipboard="Copy link to clipboard",window.T_Link_copied_to_clipboard="Copied link to clipboard!",window.T_No_results_found="No results found for \u0022{0}\u0022",window.T_N_results_found="{1} results found for \u0022{0}\u0022",baseUriFull="https://stillwater-sc.github.io/domain-flow/",window.variants&&variants.init(["blue","green","red","relearn-light","relearn-dark"])</script><script src=../../js/jquery.min.js?1675124967 defer></script></head><body class="mobile-support html" data-url=../../introduction/derivation/index.html><div id=body class=default-animation><div id=sidebar-overlay></div><div id=toc-overlay></div><nav id=topbar class=highlightable dir=ltr><div><div id=breadcrumbs><span id=sidebar-toggle-span><a href=# id=sidebar-toggle title='Menu (CTRL+ALT+n)'><i class="fas fa-bars fa-fw"></i></a></span><ol class=links itemscope itemtype=http://schema.org/BreadcrumbList><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=../../index.html><span itemprop=name>Domain Flow Architecture</span></a><meta itemprop=position content="1">></li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=../../introduction/index.html><span itemprop=name>Getting Started</span></a><meta itemprop=position content="2">></li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><span itemprop=name>Derivation</span><meta itemprop=position content="3"></li></ol></div></div></nav><main id=body-inner class="highlightable default" tabindex=-1><div class=flex-block-wrapper><div id=head-tags><div class=tags><a class=tag-link href=../../tags/derivation/index.html>derivation</a>
<a class=tag-link href=../../tags/matrix-multiply/index.html>matrix-multiply</a></div></div><p>Remember this note?</p><p>The concepts of partial and total orders are essential for finding optimal domain flow algorithms.
<a href=https://en.wikipedia.org/wiki/Partially_ordered_set target=_blank>Poset</a> are the
source of potentially interesting solutions to high-performance, low-power execution patterns.</p><p>The Linear Algebra universe is particularly rich in partial orders, something that has been exploited for centuries. <sup><a href=#history>1</a></sup>
Fortunately, for our discussion we can focus on the last couple of decades.
The book on computing with matrices is written by Golub, and van Loan <sup>[2](#matrix computations)</sup>. What follows may be
a bit technical to communicate in mathematical terms what is going on, but keep in mind the visualizations of the previous
pages as you try to visualize what the math implies.</p><p>We want to evaluate the matrix-matrix multiplication: $$ C = AB $$ where $A$, $B$, and $C$ are $N \times N$ matrices.
We picked the square matrix version because it is simpler, but all that will follow will work just as well when the
matrices are rectangular.</p><p>Matrix operations exhibits many independent operations. For example, there are four basic vector operations: <em><em>scale</em></em>, <em><em>add</em></em>,
<em><em>multiply</em></em>, and <em><em>dot product</em></em>. The operator $z = alpha * x + y$ is frequently used, and although redundant, tends
to be added as the fifth operator, and referred to as the <em>saxpy</em> operator for &ldquo;Scalar Alpha X Plus Y&rdquo;. The <em>dot product</em>
is also referred to as the <em>inner product</em>. The <em>inner product</em> is an operator that collapses two vectors into a scalar.
The <em>outer product</em> is an operator that expands two vectors into a matrix: for vector $x$ and $y$, the outer product $\times$ is defined as: $xy^T$.</p><p>Matrix operations can be expressed in terms of these vector operators with many degrees of freedom.
For example, &lsquo;double loop&rsquo; matrix-vector multiplication can be arranged in $2! = 2$ different ways;
we can evaluate the inner products, or we can evaluate the outer products.</p><p>&lsquo;Triple loop&rsquo; matrix-matrix multiplication can be arranged in $3! = 6$ ways. These arrangements have their own operators
and their own modes of access, and thus the interplay with a spatial distribution of the rows and columns of the matrices is key to
evaluate the efficiency of the computation. The orderings and properties of these different arrangements is shown in Table 1:</p><table><thead><tr><th>Loop order</th><th>Inner Loop</th><th>Middle Loop</th><th>Inner Loop Data Access</th></tr></thead><tbody><tr><td>ijk</td><td>dot</td><td>vector $\times$ matrix</td><td><em>A</em> by row, <em>B</em> by column</td></tr><tr><td>jik</td><td>dot</td><td>matrix $\times$ vector</td><td><em>A</em> by row, <em>B</em> by column</td></tr><tr><td>ikj</td><td>saxpy</td><td>row gaxpy</td><td><em>B</em> by row</td></tr><tr><td>jki</td><td>saxpy</td><td>column gaxpy</td><td><em>A</em> by column</td></tr><tr><td>kij</td><td>saxpy</td><td>row outer product</td><td><em>B</em> by row</td></tr><tr><td>kji</td><td>saxpy</td><td>column outer product</td><td><em>A</em> by column</td></tr></tbody></table><p><em>Table 1:</em> Matrix Multiplication: Orderings and Properties (see <sup>[2](#matrix computations)</sup>)</p><p>The <em><em>scale</em></em>, <em><em>add</em></em>, and <em><em>multiply</em></em> operators are highly parallel in that each individual vector element operation
is independent of each other. The <em><em>dot</em></em> product adds a consolidation, or <em>contraction</em> phase to yield a single valued result.
In a parallel context, all these vector operators have an information distribution phase that is non-trivial. First,
vectors must be embedded in space, and secondly, the vectors need to be aligned so that these element operations
can commence. Progressing to matrix operators, we have vectors of vectors that need to be aligned. For the domain
flow algorithm we demonstrated, we started from the matrix-multiply expression as $N^2$ independent <em>dot</em> products.
In mathematical terms: if we partition the $A$ matrix in rows, and the $B$ matrix in columns:</p><p>$$A = \begin{bmatrix} a_1^T \\ a_2^T \\ \vdots \\ a_n^T \end{bmatrix}$$</p><p>and</p><p>$$B = \begin{bmatrix} b_1 & b_2 & \cdots & b_n \end{bmatrix}$$</p><p>then matrix multiplication can be expressed as the collection of <em>dot</em> products:</p><p>$$\text{for i = 1:N} \\ \qquad \text{for j = 1:N} \\ \qquad\qquad c_{ij} = a_i^T b_j $$</p><p>Looking just at the individual <em>dot</em> product, a theoretical computer scientist would say: The fastest way to evaluate
a <em>dot</em> product is through a binary tree of depth $log(N)$ yielding the result in $log(N)$ steps. A spec is written
and handed off to a hardware engineer. When the hardware engineer looks at this problem, a very different view emerges.
In the hardware world, an algebraic operator such as multiply or add evaluates, depending on the number system,
in the order of <em>1 nsec</em>. But sending the result across even a modestly sized chip, say 10x10 mm, can take 10 times
as long. If the result needs to be communicated across the network, it can take a 1,000,000 times longer. With modern
chip technology, it takes about the same time to compute a multiply or add as it does to communicate the
result to a local neighborhood. From the perspective of electrons participating in the evaluation of an algebraic operator,
computation and communication are roughly equal in terms of time and thus distance these electrons can &lsquo;drift&rsquo;.</p><p>What this means for evaluating the <em>dot</em> product is that the evaluation of $$c_{ij} = \sum\limits_{k=1}^N a_{ik} * b_{kj}$$
can be executed efficiently as a propagation through local neighborhoods of communicating functional units. In mathematical
terms we can write this as a recurrence: $$c_{ijk} = c_{ijk-1} + a_{ik} * b_{kj}$$
You can start to recognize the domain flow algorithm as presented in our example. However, if we distribute the $c_{ij}$
propagation in that $k$-dimension, then accesses to $a_{ik}$ and $b_{kj}$ are not local at all. Is there a mechanism
to get the correct $a$ and $b$ elements to the right location?</p><p>Let&rsquo;s take a look at the dot products for $c_{1,1}$, $c_{1,2}$, and $c_{2,1}$. Visualize the propagation of the $c$
recurrence along the $k$-dimension above the point $i = 1, j = 1, k = 0$. Let&rsquo;s position the row of $A$, $a_1^T$, alongside
the $c_{1,1}$ propagation in the $j = 0$ plane. Thus, $a_{1,1}$ is presented at the lattice point $(1,0,1)$, and $a_{1,N}$ is positioned
at the lattice point $(1,0,N)$. Similarly, let&rsquo;s position the column of $B$, $b_1$, alongside the $c_{1,1}$ propagation,
but position it in the $i = 0$ plane. That would imply that $b_{1,1}$ is presented at the lattice point $(0,1,1)$,
and $b_{N,1}$ is positioned at the lattice point $(0,1,N)$. This would transform the recurrence equation for $_{1,1}$ into:</p><p>$$c_{1,1,k} = c_{1,1,k-1} + a_{1,0,k} * b_{0,1,k}$$</p><p>This recurrence represents all local neighborhood operand communications.</p><p>If we now visualize the recurrence for $c_{1,2}$ to propagate in the $k$-column above the lattice point $(1,2,0)$ we
recognize that for $c_{1,2}$ we need the same row vector of $A$ as the recurrence for $c_{1,1}$. We can thus propagate
the elements of the row vector $a_1^T$ along the $j$-direction and build up one side of the <em>dot</em> products for the row $c_1^T$.
Generalized to the whole $A$ matrix, this is a set of propagation recurrences defined by: $$ a_{i,j,k} = a_{i,j-1,k}$$.
Similarly, the column vector $b_1^T$ is shared between the recurrence of $c_{1,1}$ and $c_{2,1}$, and we can propagate
the elements of the column vector $b_1^T$ along the $i$-direction and build up the other side of the <em>dot</em> products
for the column $c_1$.
Generalized to the whole $B$ matrix, this is a set of propagation recurrences defined by: $$ b_{i,j,k} = b_{i-1,j,k}$$.
Once we have the $A$ and $B$ matrix elements distributed throughout the lattice, we can finally transform the $c$ recurrence
into a local neighborhood operand communication as well:</p><p>$$c_{i,j,k} = c_{i,j,k-1} + a_{i,j-1,k} * b_{i-1,j,k}$$</p><p>This completes the transformation to all local neighborhood operand communications with the
system of recurrences we have seen before expressed as a domain flow program:</p><pre tabindex=0><code>
compute ( (i,j,k) | 1 &lt;= i,j,k &lt;= N ) {
    a: a[i,j-1,k]
    b: b[i-1,j,k]
    c: c[i,j,k-1] + a[i,j-1,k] * b[i-1,j,k]
}
    
</code></pre><p><a name=history>1</a>: <a href=http://www-groups.dcs.st-and.ac.uk/history/HistTopics/Matrices_and_determinants.html target=_blank>History of Matrices and Determinants</a></p><p><a name="matrix computations">2</a>: <a href=https://www.cs.cornell.edu/cv/GVL4/golubandvanloan.htm target=_blank>Matrix Computations, Gene Golub and Charles van Loan</a></p></div></main></div><aside id=sidebar class=default-animation dir=ltr><div id=header-wrapper class=default-animation><div id=header class=default-animation><a href=https://stillwater-sc.github.io/domain-flow><img src=https://stillwater-sc.github.io/domain-flow/images/stillwater-logo.png alt="Stillwater Supercomputing, Inc."></a></div><form action=../../search.html method=get><div class="searchbox default-animation"><button type=submit title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
<label class=a11y-only for=search-by>Search</label>
<input data-search-input id=search-by name=search-by class=search-by type=search placeholder=Search...>
<span data-search-clear><i class="fas fa-times"></i></span></div></form><script>var contentLangs=["en"]</script><script src=../../js/auto-complete.js?1675124967 defer></script>
<script src=../../js/lunr/lunr.min.js?1675124967 defer></script>
<script src=../../js/lunr/lunr.stemmer.support.min.js?1675124967 defer></script>
<script src=../../js/lunr/lunr.multi.min.js?1675124967 defer></script>
<script src=../../js/lunr/lunr.en.min.js?1675124967 defer></script>
<script src=../../js/search.js?1675124967 defer></script></div><div id=content-wrapper class=highlightable><ul class=topics><li data-nav-id=/introduction/index.html class="dd-item parent alwaysopen"><a href=../../introduction/index.html>Getting Started</a><ul id=subsections-db5db1cf4b1800282ddcebf5cde99c36><li data-nav-id=/introduction/example/index.html class=dd-item><a href=../../introduction/example/index.html>An Example</a></li><li data-nav-id=/introduction/parallel-programming/index.html class=dd-item><a href=../../introduction/parallel-programming/index.html>Parallel Programming</a></li><li data-nav-id=/introduction/spacetime/index.html class=dd-item><a href=../../introduction/spacetime/index.html>Spacetime</a></li><li data-nav-id=/introduction/computational-spacetime/index.html class=dd-item><a href=../../introduction/computational-spacetime/index.html>Computational Spacetime</a></li><li data-nav-id=/introduction/domain-flow/index.html class=dd-item><a href=../../introduction/domain-flow/index.html>Domain Flow</a></li><li data-nav-id=/introduction/freeschedule/index.html class=dd-item><a href=../../introduction/freeschedule/index.html>Free Schedule</a></li><li data-nav-id=/introduction/linearschedule/index.html class=dd-item><a href=../../introduction/linearschedule/index.html>Linear Schedules</a></li><li data-nav-id=/introduction/derivation/index.html class="dd-item active"><a href=../../introduction/derivation/index.html>Derivation</a></li><li data-nav-id=/introduction/nextsteps/index.html class=dd-item><a href=../../introduction/nextsteps/index.html>Next Steps</a></li><li data-nav-id=/introduction/webgl/index.html class=dd-item><a href=../../introduction/webgl/index.html>Webgl</a></li></ul></li><li data-nav-id=/design/index.html class="dd-item alwaysopen"><a href=../../design/index.html>Elements of Good Design</a><ul id=subsections-d25739b54eec6c54b486058b3e2f3701><li data-nav-id=/design/currentstate/index.html class=dd-item><a href=../../design/currentstate/index.html>Algorithm Dynamics</a></li><li data-nav-id=/design/elements/index.html class=dd-item><a href=../../design/elements/index.html>Elements of Design</a></li><li data-nav-id=/design/dfm/index.html class=dd-item><a href=../../design/dfm/index.html>Data Flow Machine</a></li><li data-nav-id=/design/time/index.html class=dd-item><a href=../../design/time/index.html>Time: the when</a></li><li data-nav-id=/design/space/index.html class=dd-item><a href=../../design/space/index.html>Space: the where</a></li><li data-nav-id=/design/nextsteps/index.html class=dd-item><a href=../../design/nextsteps/index.html>Next Steps</a></li></ul></li><li data-nav-id=/blas/index.html class="dd-item alwaysopen"><a href=../../blas/index.html>Basic Linear Algebra</a><ul id=subsections-c04c91366fb5eba2efaaddab304f1204><li data-nav-id=/blas/level1/index.html class=dd-item><a href=../../blas/level1/index.html>BLAS Level 1</a></li><li data-nav-id=/blas/level2/index.html class=dd-item><a href=../../blas/level2/index.html>BLAS Level 2</a></li><li data-nav-id=/blas/level3/index.html class=dd-item><a href=../../blas/level3/index.html>BLAS Level 3</a></li></ul></li><li data-nav-id=/factorization/index.html class="dd-item alwaysopen"><a href=../../factorization/index.html>Matrix Factorization</a><ul id=subsections-ad68331fc764b7acec0f1f237c6522bf><li data-nav-id=/factorization/factorization/index.html class=dd-item><a href=../../factorization/factorization/index.html>Matrix Factorizations</a></li></ul></li><li data-nav-id=/matrixkernels/index.html class="dd-item alwaysopen"><a href=../../matrixkernels/index.html>Matrix Kernels</a><ul id=subsections-7c2bfc25d3abc9a62b3397c74cd33be7><li data-nav-id=/matrixkernels/matrixkernels/index.html class=dd-item><a href=../../matrixkernels/matrixkernels/index.html>Matrix Kernels</a></li></ul></li><li data-nav-id=/linearsolvers/index.html class="dd-item alwaysopen"><a href=../../linearsolvers/index.html>Linear Solvers</a><ul id=subsections-5d80ff15816d384ff301e1b89749e656><li data-nav-id=/linearsolvers/solvers/index.html class=dd-item><a href=../../linearsolvers/solvers/index.html>Linear Solvers</a></li><li data-nav-id=/linearsolvers/lu/index.html class=dd-item><a href=../../linearsolvers/lu/index.html>Gaussian Elimination</a></li></ul></li></ul><div class="footermargin footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showVariantSwitch showFooter"></div><hr class="default-animation footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showVariantSwitch showFooter"><div id=prefooter class="footerLangSwitch footerVariantSwitch footerVisitedLinks showVariantSwitch"><ul><li id=select-language-container class=footerLangSwitch><div class="padding select-container"><i class="fas fa-language fa-fw"></i>
<span>&nbsp;</span><div class=select-style><label class=a11y-only for=select-language>Language</label>
<select id=select-language onchange="location=baseUri+this.value"></select></div><div class=select-clear></div></div></li><li id=select-variant-container class="footerVariantSwitch showVariantSwitch"><div class="padding select-container"><i class="fas fa-paint-brush fa-fw"></i>
<span>&nbsp;</span><div class=select-style><label class=a11y-only for=select-variant>Theme</label>
<select id=select-variant onchange=window.variants&&variants.changeVariant(this.value)><option id=blue value=blue selected>Blue</option><option id=green value=green>Green</option><option id=red value=red>Red</option><option id=relearn-light value=relearn-light>Relearn Light</option><option id=relearn-dark value=relearn-dark>Relearn Dark</option></select></div><div class=select-clear></div></div><script>window.variants&&variants.markSelectedVariant()</script></li><li class=footerVisitedLinks><button class=padding onclick=clearHistory()><i class="fas fa-history fa-fw"></i> Clear History</button></li></ul></div><div id=footer class="footerFooter showFooter"><p>Built with <a href=https://github.com/McShelby/hugo-theme-relearn title=love><i class="fas fa-heart"></i></a> by <a href=https://gohugo.io/>Hugo</a></p></div></div></aside><script src=../../js/clipboard.min.js?1675124967 defer></script>
<script src=../../js/perfect-scrollbar.min.js?1675124967 defer></script>
<script src=../../js/featherlight.min.js?1675124967 defer></script>
<script src=../../js/theme.js?1675124967 defer></script></body></html>